

# batch_size:       64 # how many independent sequences will we process in parallel?
batch_size:       32 # how many independent sequences will we process in parallel?
block_size:       256 # what is the maximum context length for predictions?
max_iters:        5000
eval_interval:    500
learning_rate:    0.0003
eval_iters:       200
embeddings_size:  384
head_count:       6
n_layer:          6
dropout:          0.2
seed:             1337
